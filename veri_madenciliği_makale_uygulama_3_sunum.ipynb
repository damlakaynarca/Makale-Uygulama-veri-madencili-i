{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMDKUzh88QXje6Tgu1aTwlg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/damlakaynarca/Makale-Uygulama-veri-madencili-i/blob/main/veri_madencili%C4%9Fi_makale_uygulama_3_sunum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9Tl_kmzZ9_b",
        "outputId": "69f9f9c8-695b-4595-aafa-2a55cef43227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting boruta\n",
            "  Downloading Boruta-0.4.3-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.5.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (3.5.0)\n",
            "Downloading Boruta-0.4.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.9/57.9 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: boruta\n",
            "Successfully installed boruta-0.4.3\n",
            "Random Forest Feature Importance ile Özellik Seçimi\n",
            "Boruta Özellik Seçimi\n",
            "Recursive Feature Elimination (RFE)\n",
            "\n",
            "Random Forest ile Seçilen Özelliklerle Performans:\n",
            "Random Forest: Accuracy = 0.9029, Kappa = 0.4757\n",
            "SVM: Accuracy = 0.8993, Kappa = 0.2753\n",
            "KNN: Accuracy = 0.8859, Kappa = 0.3776\n",
            "LDA: Accuracy = 0.9005, Kappa = 0.4276\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Accuracy = 0.9041, Kappa = 0.4203\n",
            "Gradient Boosting: Accuracy = 0.9090, Kappa = 0.5008\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost: Accuracy = 0.9005, Kappa = 0.4213\n",
            "XGBoost: Accuracy = 0.9090, Kappa = 0.5110\n",
            "\n",
            "Boruta ile Seçilen Özelliklerle Performans:\n",
            "Random Forest: Accuracy = 0.8956, Kappa = 0.4637\n",
            "SVM: Accuracy = 0.8883, Kappa = 0.0166\n",
            "KNN: Accuracy = 0.8847, Kappa = 0.3677\n",
            "LDA: Accuracy = 0.8908, Kappa = 0.4161\n",
            "Logistic Regression: Accuracy = 0.8981, Kappa = 0.3801\n",
            "Gradient Boosting: Accuracy = 0.9053, Kappa = 0.5136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost: Accuracy = 0.8908, Kappa = 0.4041\n",
            "XGBoost: Accuracy = 0.8956, Kappa = 0.4476\n",
            "\n",
            "RFE ile Seçilen Özelliklerle Performans:\n",
            "Random Forest: Accuracy = 0.9029, Kappa = 0.4648\n",
            "SVM: Accuracy = 0.8993, Kappa = 0.2753\n",
            "KNN: Accuracy = 0.8859, Kappa = 0.3776\n",
            "LDA: Accuracy = 0.9029, Kappa = 0.4534\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression: Accuracy = 0.9066, Kappa = 0.4413\n",
            "Gradient Boosting: Accuracy = 0.9017, Kappa = 0.4664\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_weight_boosting.py:527: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost: Accuracy = 0.8944, Kappa = 0.3894\n",
            "XGBoost: Accuracy = 0.9078, Kappa = 0.5019\n"
          ]
        }
      ],
      "source": [
        "# Gerekli Kütüphanelerin Yüklenmesi\n",
        "!pip install boruta\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score\n",
        "from boruta import BorutaPy\n",
        "import zipfile\n",
        "import io\n",
        "import requests\n",
        "import xgboost as xgb\n",
        "\n",
        "# 1. Veri Setinin Yüklenmesi (Bank Marketing veri seti)\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip'\n",
        "response = requests.get(url)\n",
        "with zipfile.ZipFile(io.BytesIO(response.content)) as z:\n",
        "    with z.open('bank-additional/bank-additional.csv') as f:\n",
        "        df = pd.read_csv(f, sep=';', header=0)\n",
        "\n",
        "# Veriyi Hazırlama\n",
        "X = df.drop('y', axis=1)  # Hedef sütunu kaldırma\n",
        "y = df['y'].apply(lambda x: 1 if x == 'yes' else 0)  # Binary encoding\n",
        "X = pd.get_dummies(X)  # Kategorik değişkenleri sayısallaştırma\n",
        "\n",
        "# Eğitim ve Test Kümesi\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 2. Özellik Seçimi - Random Forest ile Feature Importance\n",
        "print(\"Random Forest Feature Importance ile Özellik Seçimi\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "feature_importances = rf.feature_importances_\n",
        "important_features_rf = X_train.columns[feature_importances > np.mean(feature_importances)]\n",
        "\n",
        "# 3. Boruta ile Özellik Seçimi\n",
        "print(\"Boruta Özellik Seçimi\")\n",
        "boruta = BorutaPy(rf, n_estimators='auto', verbose=0, random_state=42)\n",
        "boruta.fit(X_train.values, y_train.values)\n",
        "important_features_boruta = X_train.columns[boruta.support_]\n",
        "\n",
        "# 4. RFE (Recursive Feature Elimination) ile Özellik Seçimi\n",
        "print(\"Recursive Feature Elimination (RFE)\")\n",
        "rfe = RFE(rf, n_features_to_select=10)\n",
        "rfe.fit(X_train, y_train)\n",
        "important_features_rfe = X_train.columns[rfe.support_]\n",
        "\n",
        "# 5. Model Eğitimi ve Değerlendirme\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
        "    'SVM': SVC(kernel='rbf', C=1, gamma='scale'),\n",
        "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
        "    'LDA': LinearDiscriminantAnalysis(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=500, random_state=42),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
        "    'AdaBoost': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
        "    'XGBoost': xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
        "}\n",
        "\n",
        "# Fonksiyon: Model Performansını Değerlendirme\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    kappa = cohen_kappa_score(y_test, y_pred)\n",
        "    return accuracy, kappa\n",
        "\n",
        "# Seçilen Özelliklerle Modellerin Performansı\n",
        "for method, features in zip(['Random Forest', 'Boruta', 'RFE'],\n",
        "                            [important_features_rf, important_features_boruta, important_features_rfe]):\n",
        "    print(f\"\\n{method} ile Seçilen Özelliklerle Performans:\")\n",
        "    for model_name, model in models.items():\n",
        "        acc, kappa = evaluate_model(model, X_train[features], X_test[features], y_train, y_test)\n",
        "        print(f\"{model_name}: Accuracy = {acc:.4f}, Kappa = {kappa:.4f}\")\n"
      ]
    }
  ]
}